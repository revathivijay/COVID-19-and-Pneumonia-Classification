{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OItybWl1YWNm",
        "yBFM4ateVx2c",
        "NGtpskjGYejt",
        "TW7L3kWPqIfj",
        "vHPPxbRyqTEm",
        "27znPxaMZYhI",
        "LgO5SCNXZa1i",
        "zqIKyjVCZoet",
        "hJADRWQOrAGv",
        "dtTl3Gkmsprt",
        "rfIZcudyUkWx",
        "CRP0T2Krtb0F",
        "VQ36b0DNtBN9",
        "W9dz_xlbZf3X",
        "KZwfykZWZh7d",
        "6BS5_5fgZkjn",
        "N5u2pO_c14TL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdZcxFluqAfr",
        "outputId": "e49913b6-6f70-403f-ec37-ce30ea14b369"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFBGfk9TqeeT",
        "outputId": "6ac51f26-2c94-40a1-94d9-9df60ec1d287"
      },
      "source": [
        "cd '/content/gdrive/Shareddrives/520 - Machine Learning Project/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/Shareddrives/520 - Machine Learning Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lvP8Pz8mRkl"
      },
      "source": [
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "# load and show an image with Pillow\n",
        "from PIL import Image\n",
        "import sklearn\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.utils.validation import check_random_state\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import multilabel_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfUl_mJZWLs8"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slxb02c_Er2u"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pYE5bJuYNH1"
      },
      "source": [
        "## READING THE DATA AND TRIVIAL MANIPULATIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6nFaARfpbc8",
        "outputId": "6f8097f8-6754-4a39-cee1-059be77f1167"
      },
      "source": [
        "# setting paths \n",
        "BASE_DIR = 'Dataset/'\n",
        "\n",
        "NORMAL_DIR = os.path.join(BASE_DIR + 'Normal/')\n",
        "PNEUMONIA_DIR = os.path.join(BASE_DIR + 'Viral Pneumonia/')\n",
        "COVID_DIR = os.path.join(BASE_DIR + 'COVID/')\n",
        "\n",
        "print(len(os.listdir(NORMAL_DIR)))\n",
        "print(len(os.listdir(PNEUMONIA_DIR)))\n",
        "print(len(os.listdir(COVID_DIR)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1230\n",
            "1345\n",
            "2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting paths - Small dataset (used to train TL model)\n",
        "BASE_DIR = 'Dataset/'\n",
        "\n",
        "SMALL_NORMAL_DIR = os.path.join(BASE_DIR + 'Normal2/')\n",
        "SMALL_PNEUMONIA_DIR = os.path.join(BASE_DIR + 'Viral_Pneumonia2/')\n",
        "SMALL_COVID_DIR = os.path.join(BASE_DIR + 'COVID2/')\n",
        "\n",
        "print(len(os.listdir(SMALL_NORMAL_DIR)))\n",
        "print(len(os.listdir(SMALL_PNEUMONIA_DIR)))\n",
        "print(len(os.listdir(SMALL_COVID_DIR)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkZ4HpChN6nY",
        "outputId": "dbd9b620-da5e-4b49-d4bc-05326742bd82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "500\n",
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uWpJ6bV1HuT"
      },
      "source": [
        "# Reading the data\n",
        "loaded_images = []\n",
        "normal = []\n",
        "pneumonia = []\n",
        "covid = []\n",
        "labels = []\n",
        "IMG_SIZE = 299"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co3SjR_uwg0-"
      },
      "source": [
        "for filename in os.listdir(NORMAL_DIR):\n",
        "\t# load image\n",
        "  img_data = Image.open(NORMAL_DIR + filename)\n",
        "  img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "  img_data = img_data.convert(\"RGB\")\n",
        "\t# store loaded image\n",
        "  loaded_images.append(img_data)\n",
        "  normal.append(img_data)\n",
        "  labels.append(0)\n",
        "\n",
        "for filename in os.listdir(COVID_DIR):\n",
        "  # load image\n",
        "  img_data = Image.open(COVID_DIR + filename)\n",
        "  img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "  img_data = img_data.convert(\"RGB\")\n",
        "\t# store loaded image\n",
        "  loaded_images.append(img_data)\n",
        "  covid.append(img_data)\n",
        "  labels.append(1)\n",
        "\n",
        "for filename in os.listdir(PNEUMONIA_DIR):\n",
        "  # load image\n",
        "  img_data = Image.open(PNEUMONIA_DIR + filename)\n",
        "  img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "  img_data = img_data.convert(\"RGB\")\n",
        "\t# store loaded image\n",
        "  loaded_images.append(img_data)\n",
        "  pneumonia.append(img_data)\n",
        "  labels.append(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PkmKxmSyirv",
        "outputId": "74d59fce-3140-497f-f4ef-6059965a7373"
      },
      "source": [
        "print(len(labels))\n",
        "print(len(loaded_images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4575\n",
            "4575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQnrzt5a34iw"
      },
      "source": [
        "def convert_and_flatten(image):\n",
        "  image = np.asarray(image)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = image.flatten()\n",
        "  # print(image.shape)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ZejS_Y3pWG"
      },
      "source": [
        "X = [convert_and_flatten(image) for image in loaded_images]\n",
        "y = np.array(labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alj5HPey8eLd",
        "outputId": "694feba9-37d0-4f22-ce13-92e813b6e856"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3660\n",
            "915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq8dVyYKEEVT",
        "outputId": "b4e69949-eb7d-4761-c2a7-e057d3e0f41d"
      },
      "source": [
        "print(np.asarray(loaded_images[0]).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(299, 299, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-VV39BeHqhA",
        "outputId": "40c14888-8ffa-47a3-8400-fb4a6e087cb8"
      },
      "source": [
        "print(X_train[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(89401,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def read_data(class_name, IMG_SIZE=299, NORMAL_DIR=NORMAL_DIR, COVID_DIR=COVID_DIR, PNEUMONIA_DIR=PNEUMONIA_DIR):\n",
        "#   loaded_images = []\n",
        "#   labels = []\n",
        "#   for filename in os.listdir(NORMAL_DIR):\n",
        "#       img_data = Image.open(NORMAL_DIR + filename)\n",
        "#       img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "#       img_data = img_data.convert(\"RGB\")\n",
        "#       loaded_images.append(img_data)\n",
        "#       labels.append(0)\n",
        "    \n",
        "#   if class_name =='covid':\n",
        "#     for filename in os.listdir(COVID_DIR):\n",
        "#       img_data = Image.open(COVID_DIR + filename)\n",
        "#       img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "#       img_data = img_data.convert(\"RGB\")\n",
        "#       loaded_images.append(img_data)\n",
        "#       labels.append(1)\n",
        "  \n",
        "#   elif class_name == 'pneumonia':\n",
        "#     for filename in os.listdir(PNEUMONIA_DIR):\n",
        "#       img_data = Image.open(PNEUMONIA_DIR + filename)\n",
        "#       img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "#       img_data = img_data.convert(\"RGB\")\n",
        "#       loaded_images.append(img_data)\n",
        "#       labels.append(1)\n",
        "\n",
        "#   return loaded_images, labels"
      ],
      "metadata": {
        "id": "z3BGjG7NU0xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OItybWl1YWNm"
      },
      "source": [
        "## EXPLORATORY DATA ANALYSIS, PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "mPMWOMvFYVDT",
        "outputId": "27b42d12-1ac6-4230-d48d-c7b0717177b0"
      },
      "source": [
        "#Samples per class\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "x = ['Normal', 'COVID', 'Viral Pneumonia']\n",
        "y = [len(os.listdir(SMALL_NORMAL_DIR)), len(os.listdir(SMALL_COVID_DIR)), len(os.listdir(SMALL_PNEUMONIA_DIR))]\n",
        "ax.bar(x,y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whuFs0gjbyiE"
      },
      "source": [
        "INFERENCE AND ASSUMPTIONS GOING FORWARD:\n",
        "\n",
        "1.   For this application, the main goal is to recognise Covid-19 patients. It will be interesting to see if the model will have greater difficulty in identifying Pneumonia or Covid samples.\n",
        "2.   Similar to other health conditions, prediction problems or unbalanced datasets, it is necessary to prioritise Precision or Recall, since Accuracy can be misleading. The F1-Score is also a reasonable option."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis - different forms, what is needed:\n",
        "---\n",
        "\n",
        "**Baseline Models**\n",
        "---\n",
        "\n",
        "1. No-model (mode of the data)\n",
        "\n",
        "2. Logistic Regression (with hyperparameter tuning)\n",
        "\n",
        "3. Decision Trees (with hyperparameter tuning)\n",
        "\n",
        "4. KNN (Change the value of k=1:20)\n",
        "\n",
        "5. Ensemble Methods (Random Forest, Bagging, ExtraTreeClassifier) \n",
        "\n",
        "**Metrics**\n",
        "\n",
        "---\n",
        "\n",
        "1.   Recall\n",
        "2.   F1 Score\n",
        "3.   ROC AUC\n",
        "4.   Accuracy\n",
        "5.   Precision\n",
        "\n",
        "**Inferences/TODOs**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Which has the highest recall - best model among baseline models\n",
        "2. Size of dataset\n",
        "3. Effect of Regularization\n",
        "4. Overfitting in DTs\n",
        "5. Effect of Hyperparameter tuning\n",
        "6. Effect of Feature Scaling\n",
        "7. Effect on unseen data (new dataset)\n",
        "8. Individual class precision and recall (for Pneumonia and COVID only)\n",
        "9. Training all together, vs training separately\n",
        "\n"
      ],
      "metadata": {
        "id": "Ppebq-lbLrXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### confusion matrix params"
      ],
      "metadata": {
        "id": "yBFM4ateVx2c"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kYo7qdvWfI7"
      },
      "source": [
        "def extract_metrics(confusion_matrix):\n",
        "  scores = {0:{}, 1:{}, 2:{}}\n",
        "  for i in range(len(confusion_matrix)):\n",
        "    matrix = confusion_matrix[i]\n",
        "    TN = matrix[0][0]\n",
        "    FP = matrix[0][1]\n",
        "    FN = matrix[1][0]\n",
        "    TP = matrix[1][1]\n",
        "    total = TP + TN + FP + FN\n",
        "    accuracy = (TP+TN)/total\n",
        "    precision = (TP)/(TP + FP)\n",
        "    recall = TP/(TP + FN)\n",
        "    f1 = (2*precision*recall)/(precision + recall)\n",
        "    scores[i]['accuracy'] = accuracy\n",
        "    scores[i]['recall'] = recall\n",
        "    scores[i]['precision'] = precision\n",
        "    scores[i]['f1'] = f1\n",
        "  return scores\n",
        "\n",
        "def overall_metrics(confusion_matrix):\n",
        "  pass\n",
        "\n",
        "def print_metrics(scores):\n",
        "  for i in range(len(scores)):\n",
        "    score_curr = scores[i]\n",
        "    print(f\"Class {i} \\n Accuracy: {score_curr['accuracy']} \\n Precision: {score_curr['precision']} \\n Recall: {score_curr['recall']} \\n f1: {score_curr['f1']}\")\n",
        "    print()\n",
        "\n",
        "def perform_metric_calculations(confusion_matrix):\n",
        "  scores = extract_metrics(confusion_matrix)\n",
        "  # overall_scores = overall_metrics(confusion_matrix)\n",
        "  print_metrics(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 1 - Normal and Pneumonia"
      ],
      "metadata": {
        "id": "xN1UhZASUfsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the data"
      ],
      "metadata": {
        "id": "SGUGNM5zVmnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded_images, labels = read_data('pneumonia')\n",
        "# X = [convert_and_flatten(image) for image in loaded_images]\n",
        "# y = np.array(labels)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "Xv1bNMExV1Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(X_train))\n",
        "# print(len(X_test))\n",
        "# print(len(y_train))\n",
        "# print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z_1ATsJWCz6",
        "outputId": "6c66635b-84c5-457c-a22a-170d3203bf9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n",
            "200\n",
            "800\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(X_train).shape)\n",
        "print(X_train[0][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k87B7J0PresM",
        "outputId": "9d6275a8-d7fa-464c-8724-2baf1bb0cda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 268203)\n",
            "[36 36 36 42 42 42 47 47 47 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGtpskjGYejt"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Larger dataset"
      ],
      "metadata": {
        "id": "TW7L3kWPqIfj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhBfZ15bO_Wy",
        "outputId": "acc57acc-a83e-40ef-ec32-08da43cfbe86"
      },
      "source": [
        "# LOGISTIC REGRESSION WITH NO REGULARIZATION\n",
        "model = LogisticRegression(penalty='none', max_iter=100)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))\n",
        "# print(\"ROC: \", roc_auc_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.8646288209606987\n",
            "Precision:  0.8635836603223387\n",
            "Recall:  0.8646288209606987\n",
            "F1:  0.8635343427793669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCnNB2XxQIZY",
        "outputId": "a4304019-a900-4a75-f88a-0155085f65b1"
      },
      "source": [
        "# LOGISTIC REGRESSION WITH NO REGULARIZATION - INCREASE ITERATIONS\n",
        "model = LogisticRegression(penalty='none', max_iter=1000) ## did converge, but accuracy is lower\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.8427947598253275\n",
            "Precision:  0.8415638932225585\n",
            "Recall:  0.8427947598253275\n",
            "F1:  0.8406387146906567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCxf7GbpNnTI",
        "outputId": "46d47da2-444b-462d-f9d2-f30a356dc65d"
      },
      "source": [
        "# LOG REG WITH L2 PENALTY\n",
        "model = LogisticRegression(penalty='l2', max_iter=100)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.8557377049180328\n",
            "Precision:  0.8557381533434208\n",
            "Recall:  0.8557377049180328\n",
            "F1:  0.8555188946451365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXab762LPW8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224551dc-f5b7-4a2f-ff25-608c2be3526b"
      },
      "source": [
        "# LOG REGRESSION WITH FEATURE SCALING\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = LogisticRegression(penalty='none', max_iter=100)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "preds = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.8622950819672132\n",
            "Precision:  0.8611924475626406\n",
            "Recall:  0.8622950819672132\n",
            "F1:  0.8615066586593922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smaller dataset"
      ],
      "metadata": {
        "id": "vHPPxbRyqTEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGISTIC REGRESSION WITH NO REGULARIZATION\n",
        "model = LogisticRegression(penalty='none', max_iter=100)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjf6zClzqSz6",
        "outputId": "37f5be2c-4d48-4d60-cf2b-19174fbd751b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.91\n",
            "Precision:  0.93\n",
            "Recall:  0.8942307692307693\n",
            "F1:  0.911764705882353\n",
            "ROC:  0.9106570512820512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGISTIC REGRESSION WITH NO REGULARIZATION\n",
        "model = LogisticRegression(penalty='none', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dE1xLg-qWlW",
        "outputId": "183dd7db-84a1-40f9-fcce-619274fadfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.91\n",
            "Precision:  0.93\n",
            "Recall:  0.8942307692307693\n",
            "F1:  0.911764705882353\n",
            "ROC:  0.9106570512820512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGISTIC REGRESSION WITH NO REGULARIZATION\n",
        "model = LogisticRegression(penalty='l2', max_iter=100)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP-pXxv9qjEy",
        "outputId": "f8c9db17-66ce-436d-a7e7-87c4dd70e3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.91\n",
            "Precision:  0.9215686274509803\n",
            "Recall:  0.9038461538461539\n",
            "F1:  0.9126213592233009\n",
            "ROC:  0.9102564102564101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### feature scaling"
      ],
      "metadata": {
        "id": "lnkHQqDaqmcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOG REGRESSION WITH FEATURE SCALING\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = LogisticRegression(penalty='none', max_iter=100)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "preds = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muIHroVZqmP-",
        "outputId": "5fc33e01-6e3e-4302-c034-c797adfe6819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.935\n",
            "Precision:  0.941747572815534\n",
            "Recall:  0.9326923076923077\n",
            "F1:  0.9371980676328503\n",
            "ROC:  0.9350961538461539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOG REGRESSION WITH FEATURE SCALING\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = LogisticRegression(penalty='l2', max_iter=100)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "preds = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTvGN3pUquh3",
        "outputId": "b846bbc8-0603-4506-b7f0-30b7d5ee6b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.915\n",
            "Precision:  0.9306930693069307\n",
            "Recall:  0.9038461538461539\n",
            "F1:  0.9170731707317074\n",
            "ROC:  0.9154647435897436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27znPxaMZYhI"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large dataset"
      ],
      "metadata": {
        "id": "-FgeOs7Pq3za"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgO5SCNXZa1i"
      },
      "source": [
        "#### DECISION TREE WITH NO HYPERPARAMETER TUNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWoNAmcVN9Yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c72384d-d044-4b08-fd54-07e9dcc1b154"
      },
      "source": [
        "# VANILLA DT\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.774863387978142\n",
            "Precision:  0.7717349096397477\n",
            "Recall:  0.774863387978142\n",
            "F1:  0.7721365544594695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wE8IPNOOdoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb103af6-3505-42bc-da26-dff4752cb9c0"
      },
      "source": [
        "# DT with max depth = 7\n",
        "model = DecisionTreeClassifier(max_depth=7)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.7879781420765027\n",
            "Precision:  0.7866024814867287\n",
            "Recall:  0.7879781420765027\n",
            "F1:  0.7818749571210339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqIKyjVCZoet"
      },
      "source": [
        "#### DECISION TREE WITH ENTROPY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTrwTKasVDdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd337fd-b986-48ce-8138-aea908302b5d"
      },
      "source": [
        "# DT WITH ENTROPY\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.7836065573770492\n",
            "Precision:  0.7840586320152605\n",
            "Recall:  0.7836065573770492\n",
            "F1:  0.7838168217656795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Small Dataset"
      ],
      "metadata": {
        "id": "hJADRWQOrAGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VANILLA DT\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io7VecQ2rCu2",
        "outputId": "73593d68-de55-4292-e047-e77c8a8595f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.81\n",
            "Precision:  0.7894736842105263\n",
            "Recall:  0.8653846153846154\n",
            "F1:  0.8256880733944955\n",
            "ROC:  0.8076923076923077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DT\n",
        "model = DecisionTreeClassifier(max_depth=7)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF4C-9ofr7Nw",
        "outputId": "97de4a7a-5d16-4e10-e181-9f1047e8b730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.78\n",
            "Precision:  0.7678571428571429\n",
            "Recall:  0.8269230769230769\n",
            "F1:  0.7962962962962962\n",
            "ROC:  0.7780448717948718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DT WITH ENTROPY\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUfuMO-AscvS",
        "outputId": "fda30ba8-3beb-4e6b-8779-c3d5d51a3a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.78\n",
            "Precision:  0.7678571428571429\n",
            "Recall:  0.8269230769230769\n",
            "F1:  0.7962962962962962\n",
            "ROC:  0.7780448717948718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4_dfF2LZsM_"
      },
      "source": [
        "## Ensemble Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large Dataset"
      ],
      "metadata": {
        "id": "CfbIwhXasiSy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMYVCZ3cURxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd857c55-a0c0-4186-9ee4-fe853c15ef79"
      },
      "source": [
        "# ENSEMBLE METHOD\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.8994535519125683\n",
            "Precision:  0.9013981045093222\n",
            "Recall:  0.8994535519125683\n",
            "F1:  0.8971396148958636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwflU4HoUSrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90be65f2-621b-434c-c9ef-538f215f879e"
      },
      "source": [
        "# ENSEMBLE METHOD - RF\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.892896174863388\n",
            "Precision:  0.8956150745883478\n",
            "Recall:  0.892896174863388\n",
            "F1:  0.8903944831165496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNV75ZgGoOXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b77887-5165-4955-d136-7f44cfe4ac82"
      },
      "source": [
        "# ENSEMBLE METHOD - RF - HYPERPARAMETER TUNING\n",
        "model = RandomForestClassifier(n_estimators=50)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        " \n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.8950819672131147\n",
            "Precision:  0.897467939759889\n",
            "Recall:  0.8950819672131147\n",
            "F1:  0.892265464387739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKInPFXjVqEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63a16b8-7b00-4988-bce1-f03ed7c7af47"
      },
      "source": [
        "# ENSEMBLE METHOD - BAGGING\n",
        "model = BaggingClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds, average = 'weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, preds, average = 'weighted'))\n",
        "print(\"F1: \", f1_score(y_test, preds, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.8633879781420765\n",
            "Precision:  0.8628161655023652\n",
            "Recall:  0.8633879781420765\n",
            "F1:  0.8616820968742083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Small Dataset"
      ],
      "metadata": {
        "id": "dtTl3Gkmsprt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENSEMBLE METHOD\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AylkMbO7ssT7",
        "outputId": "aeec775e-1fd2-41a5-af87-500e141c93a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.95\n",
            "Precision:  0.9433962264150944\n",
            "Recall:  0.9615384615384616\n",
            "F1:  0.9523809523809524\n",
            "ROC:  0.9495192307692308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENSEMBLE METHOD - RF\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6sLHJ9QsyPZ",
        "outputId": "fe8db442-4529-4670-cb1c-d848d850b2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.93\n",
            "Precision:  0.9166666666666666\n",
            "Recall:  0.9519230769230769\n",
            "F1:  0.9339622641509433\n",
            "ROC:  0.9290865384615384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENSEMBLE METHOD - RF - HYPERPARAMETER TUNING\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFDyon_4s0oP",
        "outputId": "648c3967-9780-4fbe-c04d-78fcd2451ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.91\n",
            "Precision:  0.8909090909090909\n",
            "Recall:  0.9423076923076923\n",
            "F1:  0.9158878504672897\n",
            "ROC:  0.9086538461538461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENSEMBLE METHOD - BAGGING\n",
        "model = BaggingClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrEKrtmHs2j7",
        "outputId": "54f75435-8b15-4c7d-a831-839e28d1d8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.88\n",
            "Precision:  0.9081632653061225\n",
            "Recall:  0.8557692307692307\n",
            "F1:  0.8811881188118811\n",
            "ROC:  0.8810096153846154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2 - Normal and Covid"
      ],
      "metadata": {
        "id": "rfIZcudyUkWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reading the data"
      ],
      "metadata": {
        "id": "CRP0T2Krtb0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_images, labels = read_data('covid', IMG_SIZE=299)\n",
        "X = [convert_and_flatten(image) for image in loaded_images]\n",
        "y = np.array(labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "tBzm2bMIUl1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzJ7ubowcoBs",
        "outputId": "e63aa81a-49e4-42e7-9391-28bcca210ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n",
            "200\n",
            "800\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e162G7JMzck9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "VQ36b0DNtBN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGISTIC REGRESSION WITH NO REGULARIZATION\n",
        "model = LogisticRegression(penalty='none', max_iter=100)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yx53ZQStDVL",
        "outputId": "11e65b1f-49e3-4b7f-87b5-cf925b3fc4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.925\n",
            "Precision:  0.9238095238095239\n",
            "Recall:  0.9326923076923077\n",
            "F1:  0.9282296650717704\n",
            "ROC:  0.9246794871794872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGISTIC REGRESSION WITH NO REGULARIZATION - INCREASE ITERATIONS\n",
        "model = LogisticRegression(penalty='l2', max_iter=1000) ## did converge, but accuracy is lower\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnFYG3n7tI0L",
        "outputId": "5828e498-a8cf-44f4-e012-2e602fae5f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.925\n",
            "Precision:  0.908256880733945\n",
            "Recall:  0.9519230769230769\n",
            "F1:  0.9295774647887324\n",
            "ROC:  0.9238782051282051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOG REGRESSION WITH FEATURE SCALING\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = LogisticRegression(penalty='none', max_iter=100)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "preds = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KYctwx9tOCD",
        "outputId": "2d81646f-d2f3-4e14-9370-024a0a34ab49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.93\n",
            "Precision:  0.9326923076923077\n",
            "Recall:  0.9326923076923077\n",
            "F1:  0.9326923076923077\n",
            "ROC:  0.9298878205128206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees"
      ],
      "metadata": {
        "id": "j3BhHQTjtRuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VANILLA DT\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFgE7H_-tTXM",
        "outputId": "d0b61802-b938-4d50-c0f5-4859c1913d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.89\n",
            "Precision:  0.8942307692307693\n",
            "Recall:  0.8942307692307693\n",
            "F1:  0.8942307692307693\n",
            "ROC:  0.8898237179487178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DT\n",
        "model = DecisionTreeClassifier(max_depth=7)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPJWReU3tTTP",
        "outputId": "6005becc-aa94-4b2d-f803-4413d5eb9bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.895\n",
            "Precision:  0.8878504672897196\n",
            "Recall:  0.9134615384615384\n",
            "F1:  0.9004739336492891\n",
            "ROC:  0.8942307692307692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DT WITH ENTROPY\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXN-Q74etTLK",
        "outputId": "9bb45ff1-0574-4fe0-c4ed-596243b50f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.87\n",
            "Precision:  0.89\n",
            "Recall:  0.8557692307692307\n",
            "F1:  0.8725490196078431\n",
            "ROC:  0.8705929487179487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble methods"
      ],
      "metadata": {
        "id": "rL5gjiB_tfPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENSEMBLE METHOD\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onFcWRIptkMw",
        "outputId": "4194f890-2787-402e-c514-2a07e26794be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.955\n",
            "Precision:  0.9203539823008849\n",
            "Recall:  1.0\n",
            "F1:  0.9585253456221198\n",
            "ROC:  0.953125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENSEMBLE METHOD - RF\n",
        "model = RandomForestClassifier(n_estimators=50)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqcOOAXKtkIU",
        "outputId": "2929c5dd-9f00-413a-bea0-42905d11961d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.94\n",
            "Precision:  0.9107142857142857\n",
            "Recall:  0.9807692307692307\n",
            "F1:  0.9444444444444444\n",
            "ROC:  0.938301282051282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENSEMBLE METHOD - BAGGING\n",
        "model = BaggingClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00ekCfQNtkE8",
        "outputId": "0d729cbc-fd41-4ebf-adcf-973a6a9b59cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall scores\n",
            "-------------------------------------------\n",
            "Accuracy:  0.935\n",
            "Precision:  0.9099099099099099\n",
            "Recall:  0.9711538461538461\n",
            "F1:  0.9395348837209302\n",
            "ROC:  0.9334935897435899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unseen data - for the report"
      ],
      "metadata": {
        "id": "W9dz_xlbZf3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the data"
      ],
      "metadata": {
        "id": "KZwfykZWZh7d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woOka1rSZo3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction using different models"
      ],
      "metadata": {
        "id": "6BS5_5fgZkjn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8bLMM2jFZhT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LxYNbEbv12KO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing best models on remaining data"
      ],
      "metadata": {
        "id": "N5u2pO_c14TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal = []\n",
        "covid = []\n",
        "pneumonia = []\n",
        "labels = []\n",
        "IMG_SIZE = 299\n",
        "for filename in os.listdir(NORMAL_DIR):\n",
        "\t# load image\n",
        "  img_data = Image.open(NORMAL_DIR + filename)\n",
        "  img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "  img_data = img_data.convert(\"RGB\")\n",
        "\t# store loaded image\n",
        "  # loaded_images.append(img_data)\n",
        "  normal.append(img_data)\n",
        "  # labels.append(0)\n",
        "\n",
        "for filename in os.listdir(COVID_DIR):\n",
        "  # load image\n",
        "  img_data = Image.open(COVID_DIR + filename)\n",
        "  img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "  img_data = img_data.convert(\"RGB\")\n",
        "\t# store loaded image\n",
        "  # loaded_images.append(img_data)\n",
        "  covid.append(img_data)\n",
        "  # labels.append(1)\n",
        "\n",
        "for filename in os.listdir(PNEUMONIA_DIR):\n",
        "  # load image\n",
        "  img_data = Image.open(PNEUMONIA_DIR + filename)\n",
        "  img_data = img_data.resize((IMG_SIZE, IMG_SIZE))\n",
        "  img_data = img_data.convert(\"RGB\")\n",
        "\t# store loaded image\n",
        "  # loaded_images.append(img_data)\n",
        "  pneumonia.append(img_data)\n",
        "  # labels.append(2)\n",
        "\n",
        "normal = normal[501:]\n",
        "covid = covid[501:]\n",
        "pneumonia = pneumonia[501:]\n",
        "\n",
        "# covid first, then pneumonia\n",
        "covid_yes = True\n",
        "for i in range(len(normal)):\n",
        "  labels.append(0)\n",
        "if covid_yes:\n",
        "  for i in range(len(covid)):\n",
        "    labels.append(1)\n",
        "  data = normal + covid\n",
        "else:\n",
        "  for i in range(len(pneumonia)):\n",
        "    labels.append(1)\n",
        "  data = normal + pneumonia\n",
        "\n",
        "print(len(data))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbsBahyZ15te",
        "outputId": "35696e3f-d1dd-45fb-ed2e-2252ae4d1ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2228\n",
            "2228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VFuPwD1s4Exn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression best\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = LogisticRegression(penalty='none', max_iter=100)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "preds = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Overall scores\")\n",
        "print('-------------------------------------------')\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
        "print(\"Precision: \", precision_score(y_test, preds))\n",
        "print(\"Recall: \", recall_score(y_test, preds))\n",
        "print(\"F1: \", f1_score(y_test, preds))\n",
        "print(\"ROC: \", roc_auc_score(y_test, preds))"
      ],
      "metadata": {
        "id": "D3mGEyU83N8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}